# 背景

Distro 协议是 Nacos 社区自研的⼀种 AP 分布式协议，是面向临时实例设计的⼀种分布式协议，其保证了在某些 Nacos 节点宕机后，整个临时实例处理系统依旧可以正常工作。作为⼀种有状态的中间件应用的内嵌协议，Distro 保证了各个 Nacos 节点对于海量注册请求的统⼀协调和存储。

## 类似集群广播实现

对称服务器实现，Leader Less。

### Tomcat JGroup 实现

[https://tomcat.apache.org/tomcat-7.0-doc/cluster-howto.html](https://tomcat.apache.org/tomcat-7.0-doc/cluster-howto.html)

### Netflix Eureka
[https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication](https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication)

### Consul Gossip
[https://developer.hashicorp.com/consul/docs/architecture/gossip](https://developer.hashicorp.com/consul/docs/architecture/gossip)


# 设计思想 
Distro 协议的主要设计思想如下：

- Nacos 每个节点是平等的都可以处理写请求，同时把新数据同步到其他节点。
- 每个节点只负责部分数据，定时发送自己负责数据的校验值到其他节点来保持数据⼀致性。
- 每个节点独立处理读请求，及时从本地发出响应。

## 数据初始化
新加入的 Distro 节点会进行全量数据拉取。具体操作是轮询所有的 Distro 节点（除自身节点），通过向其他的机器发送请求拉取全量数据。
![IMG_4453.JPG](https://cdn.nlark.com/yuque/0/2023/jpeg/222258/1678613301050-6da79379-28e6-40c6-bbae-07699ab1e5c0.jpeg#averageHue=%23eff0ea&from=url&id=Fgz05&name=IMG_4453.JPG&originHeight=415&originWidth=1386&originalType=binary&ratio=1&rotation=0&showTitle=false&size=81216&status=done&style=none&title=)

在全量拉取操作完成之后，Nacos 的每台机器上都维护了当前的所有注册上来的非持久化实例数据。

### 成员管理

### 全量数据请求

### 加载数据处理


## 数据校验
在 Distro 集群启动之后，各台机器之间会定期的发送心跳。心跳信息主要为各个机器上的所有数据
的元信息（之所以使用元信息，是因为需要保证网络中数据传输的量级维持在⼀个较低水平）。这
种数据校验会以心跳的形式进行，即每台机器在固定时间间隔会向其他机器发起⼀次数据校验请求。
![IMG_4454.JPG](https://cdn.nlark.com/yuque/0/2023/jpeg/222258/1678614108196-5eded056-af40-476c-bd7b-c5a4508512f7.jpeg#averageHue=%23f7f9f5&from=url&id=ZUISC&name=IMG_4454.JPG&originHeight=195&originWidth=1386&originalType=binary&ratio=1&rotation=0&showTitle=false&size=62189&status=done&style=none&title=)

⼀旦在数据校验过程中，某台机器发现其他机器上的数据与本地数据不⼀致，则会发起⼀次全量拉取请求，将数据补齐。

### 相关组件

#### 心跳处理 - MemberInfoReportTask

#### 校验任务 - DistroVerifyTimedTask

## 写操作
对于⼀个已经启动完成的 Distro 集群，在⼀次客户端发起写操作的流程中，当注册非持久化的实例
的写请求打到某台 Nacos 服务器时，Distro 集群处理的流程图如下：
![image.png](https://cdn.nlark.com/yuque/0/2023/png/222258/1678630379017-e9b0a861-9292-4556-a9f4-6be0905bfe4e.png#averageHue=%23e8ecf4&clientId=u50d51a8e-2209-4&from=paste&height=669&id=u2101ba15&name=image.png&originHeight=836&originWidth=1386&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=360823&status=done&style=none&taskId=uf51f98c2-4c2d-4b05-ba9a-9af66135706&title=&width=1108.8)

整个步骤包括几个部分（图中从上到下顺序）： 

- 前置的 Filter 拦截请求，并根据请求中包含的 IP 和 port 信息计算其所属的 Distro 责任节点， 并将该请求转发到所属的 Distro 责任节点上。 
- 责任节点上的 Controller 将写请求进行解析。 
- Distro 协议定期执行 Sync 任务，将本机所负责的所有的实例信息同步到其他节点上。

### 关联组件

#### Distro 协议前置处理器 - DistroFilter

#### Distro 请求 Tag 生成器 - DistroTagGenerator

#### Distro 请求映射器 - DistroMapper

## 读操作
由于每台机器上都存放了全量数据，因此在每⼀次读操作中，Distro 机器会直接从本地拉取数据。 快速响应。
![image.png](https://cdn.nlark.com/yuque/0/2023/png/222258/1678631705255-306b3d04-1aef-4fd7-ad6c-bd71d43bfb82.png#averageHue=%23f7f7f7&clientId=u50d51a8e-2209-4&from=paste&height=354&id=ufaceb027&name=image.png&originHeight=442&originWidth=1386&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=189118&status=done&style=none&taskId=u6fe19794-858f-44e6-abd9-b2a3a2f7698&title=&width=1108.8)
这种机制保证了 Distro 协议可以作为⼀种 AP 协议，对于读操作都进行及时的响应。在网络分区的情况下，对于所有的读操作也能够正常返回；当网络恢复时，各个 Distro 节点会把各数据分片的数据进行合并恢复。

参考 Nacos OpenAPI V2 : [https://nacos.io/zh-cn/docs/v2/guide/user/open-api.html](https://nacos.io/zh-cn/docs/v2/guide/user/open-api.html)

# 核心 API

## 协议管理 

### 核心协议- DistroProtocol

#### 依赖组件

##### 服务器成员管理器 - ServerMemberManager 

##### 组件仓库 - DistroComponentHolder

##### 任务引擎 - DistroTaskEngineHolder

#### 生命周期

##### 初始化

###### 启动任务

- 启动校验任务 - com.alibaba.nacos.core.distributed.distro.DistroProtocol#startVerifyTask

- 启动数据加载任务 - com.alibaba.nacos.core.distributed.distro.DistroProtocol#startLoadTask

###### 启动校验任务 - DistroVerifyTimedTask

###### 启动数据加载任务 - DistroLoadDataTask

## 成员管理

### 服务器成员管理器 - ServerMemberManager

#### 依赖组件

##### REST 请求客户端 - NacosAsyncRestTemplate

##### 全局执行器 - GlobalExecutor

- 定时任务 - com.alibaba.nacos.core.utils.GlobalExecutor#scheduleByCommon

#### 生命周期

##### 初始化

- 添加当前节点到 serverList（集群服务器列表）
- 监听事件 - MembersChangeEvent 
- Nacos 服务器成员查找 - MemberLookup
   - MemberLookup#lookup()
         - AbstractMemberLookup#afterLookup()
            - ServerMemberManager#memberChange()
               - 初始化 serverList，集群服务器完成列表
               - 发送 MembersChangeEvent
			   
##### Web 启动事件  - Web服务器初始化事件处理
处理 Spring Boot 事件 - WebServerInitializedEvent

###### 心跳处理 - MemberInfoReportTask

轮训所有 Nacos 服务器节点（除自身之外），发送 POST 请求

### 服务器成员查找 - MemberLookup

#### 内建实现

##### 抽象实现 - AbstractMemberLookup

###### 后置处理 
```java
    @Override
    public void afterLookup(Collection<Member> members) {
        this.memberManager.memberChange(members);
    }
```
当 lookup 操作后，调用 ServerMemberManager#memberChange() 方法。
完成的过程如下：

- ServerMemberManager#init()
   - 创建 MemberLookup
      - MemberLookup#lookup()
         - AbstractMemberLookup#afterLookup()
            - ServerMemberManager#memberChange()
               - 发送 MembersChangeEvent
##### 单机实现 - StandaloneMemberLookup
单机环境无需查找其他节点

##### 文件配置实现 - FileConfigMemberLookup
依赖于本地的配置文件 - cluster.conf

##### 地址服务器实现 - AddressServerMemberLookup
依赖于外部的地址服务器


## 数据处理

### 数据存储 - DistroDataStorage

#### 底层实现 - DistroClientDataProcessor

##### 类型 - "Nacos:Naming:v2:ClientData"

### 数据处理器 - DistroDataProcessor

#### 底层实现 - DistroClientDataProcessor

## Web 处理

### Distro 协议前置处理器 - DistroFilter
基于 Servlet Filter API 实现，实现简单一致性 Hash

#### 使用场景

##### 在当前 Distro 节点处理
```java
            String distroTag = distroTagGenerator.getResponsibleTag(req);
            
            if (distroMapper.responsible(distroTag)) {
                filterChain.doFilter(req, resp);
                return;
            }
```

##### 转发其他 Distro 节点处理
```java
            final String targetServer = distroMapper.mapSrv(distroTag);
            
            List<String> headerList = new ArrayList<>(16);
            Enumeration<String> headers = req.getHeaderNames();
            while (headers.hasMoreElements()) {
                String headerName = headers.nextElement();
                headerList.add(headerName);
                headerList.add(req.getHeader(headerName));
            }
            
            final String body = IoUtils.toString(req.getInputStream(), StandardCharsets.UTF_8.name());
            final Map<String, String> paramsValue = HttpClient.translateParameterMap(req.getParameterMap());
            
            RestResult<String> result = HttpClient
                    .request(HTTP_PREFIX + targetServer + req.getRequestURI(), headerList, paramsValue, body,
                            PROXY_CONNECT_TIMEOUT, PROXY_READ_TIMEOUT, StandardCharsets.UTF_8.name(), req.getMethod());
            String data = result.ok() ? result.getData() : result.getMessage();
            try {
                WebUtils.response(resp, data, result.getCode());
            } catch (Exception ignore) {
                Loggers.SRV_LOG.warn("[DISTRO-FILTER] request failed: " + distroMapper.mapSrv(distroTag) + urlString);
            }
```
### Distro 请求 Tag 生成器 - DistroTagGenerator
通过 HTTP 请求获取 Distro Tag
#### 内建实现

##### 基于 IP 和端口实现 - DistroIpPortTagGenerator
tag : "${IP}:${port}"

### Distro 请求映射器 - DistroMapper

#### 使用场景

##### 实现简单一致性 Hash

###### 当前节点 Hash 匹配规则
```java
    public boolean responsible(String responsibleTag) {
        final List<String> servers = healthyList;
        
        if (!switchDomain.isDistroEnabled() || EnvUtil.getStandaloneMode()) {
            return true;
        }
        
        if (CollectionUtils.isEmpty(servers)) {
            // means distro config is not ready yet
            return false;
        }
        
        String localAddress = EnvUtil.getLocalAddress();
        int index = servers.indexOf(localAddress);
        int lastIndex = servers.lastIndexOf(localAddress);
        if (lastIndex < 0 || index < 0) {
            return true;
        }
        
        int target = distroHash(responsibleTag) % servers.size();
        return target >= index && target <= lastIndex;
    }
```

##### 其他节点 Hash 匹配规则
```java
    public String mapSrv(String responsibleTag) {
        final List<String> servers = healthyList;
        
        if (CollectionUtils.isEmpty(servers) || !switchDomain.isDistroEnabled()) {
            return EnvUtil.getLocalAddress();
        }
        
        try {
            int index = distroHash(responsibleTag) % servers.size();
            return servers.get(index);
        } catch (Throwable e) {
            Loggers.SRV_LOG
                    .warn("[NACOS-DISTRO] distro mapper failed, return localhost: " + EnvUtil.getLocalAddress(), e);
            return EnvUtil.getLocalAddress();
        }
    }
```

##### MembersChangeEvent 事件监听 - 处理节点变更 
```java
    @Override
    public void onEvent(MembersChangeEvent event) {
        // Here, the node list must be sorted to ensure that all nacos-server's
        // node list is in the same order
        List<String> list = MemberUtil.simpleMembers(MemberUtil.selectTargetMembers(event.getMembers(),
                member -> NodeState.UP.equals(member.getState()) || NodeState.SUSPICIOUS.equals(member.getState())));
        Collections.sort(list);
        Collection<String> old = healthyList;
        healthyList = Collections.unmodifiableList(list);
        Loggers.SRV_LOG.info("[NACOS-DISTRO] healthy server list changed, old: {}, new: {}", old, healthyList);
    }
```


## 客户端

### 客户端管理器 - ClientManager


